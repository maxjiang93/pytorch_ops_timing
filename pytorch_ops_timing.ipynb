{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.4.0+cu100\n",
      "GPU   Type   : Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "print(f\"GPU   Type   : {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various custom implementations of slow PyTorch functions to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _colwise_max(input_tensor: torch.Tensor, \n",
    "                dim: int):\n",
    "    \"\"\"Perform column-wise max operation. Same as input_tensor.max(dim)[0].\n",
    "    \n",
    "    Orders of magnitude faster. Known bug in PyTorch.\n",
    "    \"\"\"\n",
    "    ndim = len(input_tensor.size())\n",
    "    if ndim == 1:\n",
    "        input_tensor = input_tensor.view(len(input_tensor), 1)\n",
    "    out = torch.stack(\n",
    "        [torch.max(input_tensor[:, i]) for i in range(input_tensor.shape[1 - dim])]\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def _fast_bincount(input_tensor):\n",
    "    \"\"\"A faster version of bincount than torch.bincount. Same API.\"\"\"\n",
    "    ndim = len(input_tensor.size())\n",
    "    if not ndim == 1:\n",
    "        raise ValueError(f\"input_tensor must be 1-d. Instead it is {ndim}-d.\")\n",
    "    if not (input_tensor[1:] >= input_tensor[:-1]).all():\n",
    "        input_tensor = torch.sort(input_tensor)[0]\n",
    "    diff_from_prev = input_tensor[1:] != input_tensor[:-1]\n",
    "    first_ind = torch.nonzero(diff_from_prev)[:, 0] + 1\n",
    "    inds = torch.zeros(len(first_ind) + 2, device=input_tensor.device, dtype=torch.long)\n",
    "    inds[-1] = len(input_tensor)\n",
    "    inds[1:-1] = first_ind\n",
    "    bincounts = inds[1:] - inds[:-1]\n",
    "    return bincounts\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing for column-wise max operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random input tensor\n",
    "input_tensor = torch.rand([100000, 4]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.89 ms ± 421 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "colmax = input_tensor.max(dim=0)[0]\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 µs ± 1.42 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "colmax_custom = _colwise_max(input_tensor, dim=0)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmax = input_tensor.max(dim=0)[0]\n",
    "colmax_custom = _colwise_max(input_tensor, dim=0)\n",
    "np.testing.assert_equal(to_np(colmax), to_np(colmax_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing for bincount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random input tensor\n",
    "input_tensor = torch.randint(20, size=[100000]).cuda()\n",
    "input_tensor = torch.sort(input_tensor)[0]  # for a pre-sorted input tensor, _fast_bincount is much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18 ms ± 717 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "counts = torch.bincount(input_tensor)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 µs ± 1.81 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "counts_custom = _fast_bincount(input_tensor)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that results are the same\n",
    "counts = torch.bincount(input_tensor)\n",
    "counts_custom = _fast_bincount(torch.sort(input_tensor)[0])\n",
    "np.testing.assert_equal(to_np(counts), to_np(counts_custom))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
